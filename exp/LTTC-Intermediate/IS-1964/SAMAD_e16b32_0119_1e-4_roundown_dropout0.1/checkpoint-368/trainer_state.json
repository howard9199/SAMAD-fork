{
  "best_metric": 0.6333333333333333,
  "best_model_checkpoint": "./exp/LTTC-Intermediate/IS-1964/SAMAD_e16b32_0119_1e-4_roundown/checkpoint-120",
  "epoch": 16.0,
  "eval_steps": 60,
  "global_step": 368,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.34782608695652173,
      "grad_norm": 7.692997455596924,
      "learning_rate": 9.782608695652174e-05,
      "loss": 1.4806,
      "step": 8
    },
    {
      "epoch": 0.6956521739130435,
      "grad_norm": 4.775883674621582,
      "learning_rate": 9.565217391304348e-05,
      "loss": 1.1641,
      "step": 16
    },
    {
      "epoch": 1.0434782608695652,
      "grad_norm": 8.777853965759277,
      "learning_rate": 9.347826086956522e-05,
      "loss": 1.0583,
      "step": 24
    },
    {
      "epoch": 1.391304347826087,
      "grad_norm": 3.9347457885742188,
      "learning_rate": 9.130434782608696e-05,
      "loss": 0.9724,
      "step": 32
    },
    {
      "epoch": 1.7391304347826086,
      "grad_norm": 4.634918212890625,
      "learning_rate": 8.91304347826087e-05,
      "loss": 0.9087,
      "step": 40
    },
    {
      "epoch": 2.0869565217391304,
      "grad_norm": 6.157567977905273,
      "learning_rate": 8.695652173913044e-05,
      "loss": 0.8775,
      "step": 48
    },
    {
      "epoch": 2.4347826086956523,
      "grad_norm": 6.948894500732422,
      "learning_rate": 8.478260869565218e-05,
      "loss": 0.7898,
      "step": 56
    },
    {
      "epoch": 2.608695652173913,
      "eval_accuracy": 0.5666666666666667,
      "eval_loss": 0.9984078407287598,
      "eval_runtime": 3.7179,
      "eval_samples_per_second": 24.207,
      "eval_steps_per_second": 0.807,
      "step": 60
    },
    {
      "epoch": 2.782608695652174,
      "grad_norm": 6.709256649017334,
      "learning_rate": 8.260869565217392e-05,
      "loss": 0.8937,
      "step": 64
    },
    {
      "epoch": 3.130434782608696,
      "grad_norm": 16.188068389892578,
      "learning_rate": 8.043478260869566e-05,
      "loss": 0.9035,
      "step": 72
    },
    {
      "epoch": 3.4782608695652173,
      "grad_norm": 9.075724601745605,
      "learning_rate": 7.82608695652174e-05,
      "loss": 0.7351,
      "step": 80
    },
    {
      "epoch": 3.8260869565217392,
      "grad_norm": 16.908292770385742,
      "learning_rate": 7.608695652173914e-05,
      "loss": 0.657,
      "step": 88
    },
    {
      "epoch": 4.173913043478261,
      "grad_norm": 6.984836578369141,
      "learning_rate": 7.391304347826086e-05,
      "loss": 0.5218,
      "step": 96
    },
    {
      "epoch": 4.521739130434782,
      "grad_norm": 12.242293357849121,
      "learning_rate": 7.17391304347826e-05,
      "loss": 0.5084,
      "step": 104
    },
    {
      "epoch": 4.869565217391305,
      "grad_norm": 14.008055686950684,
      "learning_rate": 6.956521739130436e-05,
      "loss": 0.6065,
      "step": 112
    },
    {
      "epoch": 5.217391304347826,
      "grad_norm": 2.366065502166748,
      "learning_rate": 6.73913043478261e-05,
      "loss": 0.3603,
      "step": 120
    },
    {
      "epoch": 5.217391304347826,
      "eval_accuracy": 0.6333333333333333,
      "eval_loss": 1.0921530723571777,
      "eval_runtime": 3.6639,
      "eval_samples_per_second": 24.564,
      "eval_steps_per_second": 0.819,
      "step": 120
    },
    {
      "epoch": 5.565217391304348,
      "grad_norm": 2.074843406677246,
      "learning_rate": 6.521739130434783e-05,
      "loss": 0.265,
      "step": 128
    },
    {
      "epoch": 5.913043478260869,
      "grad_norm": 6.235400199890137,
      "learning_rate": 6.304347826086957e-05,
      "loss": 0.5014,
      "step": 136
    },
    {
      "epoch": 6.260869565217392,
      "grad_norm": 13.099430084228516,
      "learning_rate": 6.086956521739131e-05,
      "loss": 0.2999,
      "step": 144
    },
    {
      "epoch": 6.608695652173913,
      "grad_norm": 7.6142144203186035,
      "learning_rate": 5.869565217391305e-05,
      "loss": 0.2784,
      "step": 152
    },
    {
      "epoch": 6.956521739130435,
      "grad_norm": 8.23698616027832,
      "learning_rate": 5.652173913043478e-05,
      "loss": 0.3187,
      "step": 160
    },
    {
      "epoch": 7.304347826086957,
      "grad_norm": 9.598365783691406,
      "learning_rate": 5.4347826086956524e-05,
      "loss": 0.3426,
      "step": 168
    },
    {
      "epoch": 7.6521739130434785,
      "grad_norm": 1.5792632102966309,
      "learning_rate": 5.217391304347826e-05,
      "loss": 0.2181,
      "step": 176
    },
    {
      "epoch": 7.826086956521739,
      "eval_accuracy": 0.6111111111111112,
      "eval_loss": 1.5322225093841553,
      "eval_runtime": 3.6986,
      "eval_samples_per_second": 24.334,
      "eval_steps_per_second": 0.811,
      "step": 180
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.7399702072143555,
      "learning_rate": 5e-05,
      "loss": 0.1206,
      "step": 184
    },
    {
      "epoch": 8.347826086956522,
      "grad_norm": 6.083877086639404,
      "learning_rate": 4.782608695652174e-05,
      "loss": 0.2886,
      "step": 192
    },
    {
      "epoch": 8.695652173913043,
      "grad_norm": 18.08487892150879,
      "learning_rate": 4.565217391304348e-05,
      "loss": 0.349,
      "step": 200
    },
    {
      "epoch": 9.043478260869565,
      "grad_norm": 2.1030259132385254,
      "learning_rate": 4.347826086956522e-05,
      "loss": 0.122,
      "step": 208
    },
    {
      "epoch": 9.391304347826088,
      "grad_norm": 4.166744709014893,
      "learning_rate": 4.130434782608696e-05,
      "loss": 0.121,
      "step": 216
    },
    {
      "epoch": 9.73913043478261,
      "grad_norm": 2.1816515922546387,
      "learning_rate": 3.91304347826087e-05,
      "loss": 0.1072,
      "step": 224
    },
    {
      "epoch": 10.08695652173913,
      "grad_norm": 0.5125355124473572,
      "learning_rate": 3.695652173913043e-05,
      "loss": 0.1147,
      "step": 232
    },
    {
      "epoch": 10.434782608695652,
      "grad_norm": 4.158665180206299,
      "learning_rate": 3.478260869565218e-05,
      "loss": 0.0319,
      "step": 240
    },
    {
      "epoch": 10.434782608695652,
      "eval_accuracy": 0.5666666666666667,
      "eval_loss": 2.1402533054351807,
      "eval_runtime": 3.6366,
      "eval_samples_per_second": 24.748,
      "eval_steps_per_second": 0.825,
      "step": 240
    },
    {
      "epoch": 10.782608695652174,
      "grad_norm": 6.474753379821777,
      "learning_rate": 3.260869565217392e-05,
      "loss": 0.1087,
      "step": 248
    },
    {
      "epoch": 11.130434782608695,
      "grad_norm": 10.768753051757812,
      "learning_rate": 3.0434782608695656e-05,
      "loss": 0.0527,
      "step": 256
    },
    {
      "epoch": 11.478260869565217,
      "grad_norm": 0.17936748266220093,
      "learning_rate": 2.826086956521739e-05,
      "loss": 0.036,
      "step": 264
    },
    {
      "epoch": 11.826086956521738,
      "grad_norm": 0.6888436079025269,
      "learning_rate": 2.608695652173913e-05,
      "loss": 0.0108,
      "step": 272
    },
    {
      "epoch": 12.173913043478262,
      "grad_norm": 0.5184012651443481,
      "learning_rate": 2.391304347826087e-05,
      "loss": 0.0432,
      "step": 280
    },
    {
      "epoch": 12.521739130434783,
      "grad_norm": 1.0603086948394775,
      "learning_rate": 2.173913043478261e-05,
      "loss": 0.0217,
      "step": 288
    },
    {
      "epoch": 12.869565217391305,
      "grad_norm": 2.5694949626922607,
      "learning_rate": 1.956521739130435e-05,
      "loss": 0.0202,
      "step": 296
    },
    {
      "epoch": 13.043478260869565,
      "eval_accuracy": 0.6111111111111112,
      "eval_loss": 2.8201003074645996,
      "eval_runtime": 3.6772,
      "eval_samples_per_second": 24.475,
      "eval_steps_per_second": 0.816,
      "step": 300
    },
    {
      "epoch": 13.217391304347826,
      "grad_norm": 0.5065363645553589,
      "learning_rate": 1.739130434782609e-05,
      "loss": 0.015,
      "step": 304
    },
    {
      "epoch": 13.565217391304348,
      "grad_norm": 0.3622661828994751,
      "learning_rate": 1.5217391304347828e-05,
      "loss": 0.0032,
      "step": 312
    },
    {
      "epoch": 13.91304347826087,
      "grad_norm": 0.030206497758626938,
      "learning_rate": 1.3043478260869566e-05,
      "loss": 0.015,
      "step": 320
    },
    {
      "epoch": 14.26086956521739,
      "grad_norm": 0.6593512892723083,
      "learning_rate": 1.0869565217391305e-05,
      "loss": 0.0111,
      "step": 328
    },
    {
      "epoch": 14.608695652173914,
      "grad_norm": 0.0227492842823267,
      "learning_rate": 8.695652173913044e-06,
      "loss": 0.0069,
      "step": 336
    },
    {
      "epoch": 14.956521739130435,
      "grad_norm": 0.040566712617874146,
      "learning_rate": 6.521739130434783e-06,
      "loss": 0.0062,
      "step": 344
    },
    {
      "epoch": 15.304347826086957,
      "grad_norm": 0.12558743357658386,
      "learning_rate": 4.347826086956522e-06,
      "loss": 0.0034,
      "step": 352
    },
    {
      "epoch": 15.652173913043478,
      "grad_norm": 0.19815051555633545,
      "learning_rate": 2.173913043478261e-06,
      "loss": 0.0041,
      "step": 360
    },
    {
      "epoch": 15.652173913043478,
      "eval_accuracy": 0.5666666666666667,
      "eval_loss": 3.056877613067627,
      "eval_runtime": 3.6099,
      "eval_samples_per_second": 24.931,
      "eval_steps_per_second": 0.831,
      "step": 360
    },
    {
      "epoch": 16.0,
      "grad_norm": 0.8970130681991577,
      "learning_rate": 0.0,
      "loss": 0.0051,
      "step": 368
    }
  ],
  "logging_steps": 8,
  "max_steps": 368,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 16,
  "save_steps": 60,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
